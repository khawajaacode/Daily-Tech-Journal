### Overfitting vs Underfitting

**Overfitting**
- Learns *too much* from training data (including noise)  
- Performs **well on training data** but **poorly on new data**  
- High variance, low bias  

**Underfitting**
- Learns *too little* from training data  
- Performs **poorly on both training and test data**  
- High bias, low variance  
